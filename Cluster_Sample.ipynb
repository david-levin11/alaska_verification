{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/david-levin11/alaska_verification/blob/main/Cluster_Sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iYyzL_9EAm7"
      },
      "source": [
        "**Testing ECMWF Cluster Techniques**\n",
        "<br/>\n",
        "Description--More to come later.\n",
        "\n",
        "- David Levin, Arctic Testbed & Proving Ground, Anchorage Alaska"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t56SexSlUELy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6DRBRAXCyNh"
      },
      "source": [
        "##**1 - Install and Import Packages**\n",
        "This will take about a minute to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brhZKdsjM7wZ",
        "outputId": "cd74ea16-b8c0-41bd-9846-72a95117b389",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.1.0-1/Mambaforge-23.1.0-1-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:20\n",
            "ðŸ” Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "!pip install ecmwf-opendata eccodes==2.38.3 cfgrib xarray scikit-learn cartopy\n",
        "from datetime import datetime, timezone\n",
        "from pathlib import Path\n",
        "from ecmwf.opendata import Client\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNRHFuNmC-2K"
      },
      "source": [
        "# **2 - Set Options & Download Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJaogqYCNB-Q",
        "outputId": "8ba41afa-6624-47c3-f7f9-4f2fc4f87dc6",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            " â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
            " â”‚ I'm building Herbie's default config file.      â”‚\n",
            " â•°â•¥â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
            " ðŸ‘·ðŸ»â€â™‚ï¸\n",
            " â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
            " â”‚ You're ready to go.                             â”‚\n",
            " â”‚ You may edit the config file here:              â”‚\n",
            " â”‚ /root/.config/herbie/config.toml                â”‚\n",
            " â•°â•¥â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
            " ðŸ‘·ðŸ»â€â™‚ï¸\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/site-packages/pyproj/__init__.py:89: UserWarning: pyproj unable to set database path.\n",
            "  _pyproj_global_context_initialize()\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def download_ecmwf_ens(\n",
        "    param: str,\n",
        "    init_time: datetime,\n",
        "    steps,\n",
        "    *,\n",
        "    level_type: str = \"sfc\",          # \"sfc\" or \"pl\"\n",
        "    levels=None,                      # e.g., [500] or [1000,850,700] for levtype=\"pl\"\n",
        "    members=\"all\",                    # \"all\", \"control\", \"mean\", \"stdev\", or list of ints (e.g., [1,3,5])\n",
        "    target_dir=\".\",\n",
        "    source: str = \"ecmwf\"             # \"ecmwf\", \"aws\", or \"azure\"\n",
        ") -> Path:\n",
        "    \"\"\"\n",
        "    Download ECMWF ENS data (Open Data) for a given init, variable, and steps.\n",
        "\n",
        "    Examples:\n",
        "      - Surface:   param=\"tp\", level_type=\"sfc\"\n",
        "      - Pressure:  param=\"z\",  level_type=\"pl\", levels=[500]\n",
        "      - Members:   members=\"all\" (pf), \"control\" (cf), \"mean\" (em), \"stdev\" (es), or [1,2,3]\n",
        "      - Steps:     integer, list[int], or \"0/6/240\" (MARS-style)\n",
        "    \"\"\"\n",
        "    # Normalize inputs\n",
        "    date_str = init_time.strftime(\"%Y-%m-%d\")\n",
        "    hour = int(init_time.strftime(\"%H\"))\n",
        "\n",
        "    # steps can be int, list, or MARS-style string\n",
        "    if isinstance(steps, int):\n",
        "        step_val = steps\n",
        "    elif isinstance(steps, (list, tuple)):\n",
        "        step_val = \"/\".join(str(s) for s in steps)\n",
        "    else:\n",
        "        # assume caller passed a MARS-style range like \"0/6/240\" or \"0/to/240/by/6\"\n",
        "        step_val = str(steps)\n",
        "\n",
        "    # Map members choice to ECMWF type/number\n",
        "    mtype = \"pf\"  # perturbed members by default\n",
        "    number_kw = {}\n",
        "    if isinstance(members, str):\n",
        "        m = members.lower()\n",
        "        if m == \"control\":\n",
        "            mtype = \"cf\"\n",
        "        elif m == \"mean\":\n",
        "            mtype = \"em\"\n",
        "        elif m == \"stdev\":\n",
        "            mtype = \"es\"\n",
        "        elif m == \"all\":\n",
        "            pass  # pf + no \"number\" downloads all perturbed members\n",
        "        else:\n",
        "            raise ValueError(\"members must be 'all', 'control', 'mean', 'stdev', or a list of ints.\")\n",
        "    else:\n",
        "        # explicit list of member numbers\n",
        "        mtype = \"pf\"\n",
        "        nums = list(members)\n",
        "        if not nums:\n",
        "            raise ValueError(\"members list is empty.\")\n",
        "        number_kw = {\"number\": nums}\n",
        "\n",
        "    # Level keywords\n",
        "    level_kw = {}\n",
        "    levtype = level_type.lower()\n",
        "    if levtype == \"pl\":\n",
        "        if not levels:\n",
        "            raise ValueError(\"Pressure-level request requires 'levels' (e.g., [500] or [1000,850,700]).\")\n",
        "        level_kw = {\"levtype\": \"pl\", \"levelist\": \"/\".join(str(l) for l in levels)}\n",
        "        level_label = f\"pl_{'-'.join(str(l) for l in levels)}\"\n",
        "    elif levtype == \"sfc\":\n",
        "        level_kw = {\"levtype\": \"sfc\"}\n",
        "        level_label = \"sfc\"\n",
        "    else:\n",
        "        raise ValueError(\"level_type must be 'sfc' or 'pl'.\")\n",
        "\n",
        "    # Build output filename\n",
        "    if isinstance(param, list):\n",
        "      param_key = \"_\".join(param)\n",
        "    else:\n",
        "      param_key = param\n",
        "    steps_label = str(steps) if isinstance(steps, str) else step_val.replace(\"/\", \"-\")\n",
        "    member_label = members if isinstance(members, str) else f\"m{','.join(map(str, members))}\"\n",
        "    target_dir = Path(target_dir)\n",
        "    target_dir.mkdir(parents=True, exist_ok=True)\n",
        "    outfile = target_dir / f\"ecmwf_ens_{param_key}_{level_label}_{date_str.replace('-','')}{hour:02d}.grib2\"\n",
        "\n",
        "    # Create client and request\n",
        "    client = Client(source=source)\n",
        "    req = {\n",
        "        \"date\": date_str,\n",
        "        \"time\": hour,\n",
        "        \"stream\": \"enfo\",\n",
        "        \"type\": mtype,\n",
        "        \"param\": param,\n",
        "        \"step\": step_val,\n",
        "        **level_kw,\n",
        "        **number_kw,\n",
        "        \"target\": str(outfile),\n",
        "    }\n",
        "\n",
        "    # Retrieve\n",
        "    client.retrieve(**req)\n",
        "    return outfile\n",
        "\n",
        "#@markdown What is your model run initialization date?\n",
        "init_date = \"2025-08-11\" #@param {type:\"date\"}\n",
        "#@markdown What is your model run time\n",
        "init_time = \"00\" #@param [\"00\",  \"12\"] {type:\"raw\"}\n",
        "param = \"500mb Height\"\n",
        "param_dict = {\"Total Precipitation\": \"tp\", \"500mb Height\": \"gh\", \"Surface Pressure\": \"sp\"}\n",
        "#@markdown What time frame do you want to cluster on?\n",
        "timeframe = \"Day7\" #@param [\"Day5\", \"Day6\", \"Day7\", \"Day8\", \"Day9\", \"Day5-7\", \"Day6-8\", \"Day7-9\", \"Day5-8\", \"Day6-9\"]\n",
        "timeranges = {\n",
        "    \"Day5\": (120, 144),\n",
        "    \"Day6\": (144, 168),\n",
        "    \"Day7\": (168, 192),\n",
        "    \"Day8\": (192, 216),\n",
        "    \"Day9\": (216, 240),\n",
        "    \"Day5-7\": (120, 192),\n",
        "    \"Day6-8\": (144, 216),\n",
        "    \"Day7-9\": (168, 240),\n",
        "    \"Day5-8\": (120, 216),\n",
        "    \"Day6-9\": (144, 240),\n",
        "}\n",
        "tr = timeranges[timeframe]\n",
        "\n",
        "path = download_ecmwf_ens(\n",
        "    param=param_dict[param],\n",
        "    init_time=datetime.strptime(f\"{init_date} {init_time}:00\", \"%Y-%m-%d %H:%M\"),\n",
        "    steps=list(range(0, 241, 6)),\n",
        "    level_type=\"pl\",\n",
        "    levels=[500],\n",
        "    members=\"all\",\n",
        "    target_dir=\".\",\n",
        "    source=\"ecmwf\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Perform Cluster Analysis & Plot EOF/Phase Space & Pick Representative Members**"
      ],
      "metadata": {
        "id": "6ose8X-tq4jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "\n",
        "\n",
        "def plot_mean_height_with_eof_shade_cartopy(\n",
        "    z_meters,            # xarray.DataArray [number, step, latitude, longitude] in meters\n",
        "    pca,                 # fitted PCA on stacked, âˆšcosÏ†-weighted anomalies\n",
        "    window=(120,168),    # (start_hr, end_hr)\n",
        "    eof_indices=(0,1),   # which EOFs to draw\n",
        "    projection=None,     # a cartopy CRS; default is Lambert Conformal for Alaska\n",
        "    add_states=True,\n",
        "    add_borders=True,\n",
        "    coast_res=\"50m\",\n",
        "    n_contours=20,\n",
        "    cmap=\"RdBu_r\",\n",
        "    symmetric_shade=True,\n",
        "    scale=\"1sigma\"       # \"none\" or \"1sigma\"\n",
        "):\n",
        "    # coords\n",
        "    steps = z_meters.step.values\n",
        "    lat   = z_meters.latitude.values\n",
        "    lon   = z_meters.longitude.values\n",
        "    n_steps, n_lat, n_lon = len(steps), len(lat), len(lon)\n",
        "\n",
        "    # normalize lon to [-180, 180] if needed\n",
        "    if np.nanmax(lon) > 180:\n",
        "        lon = ((lon + 180) % 360) - 180\n",
        "        z_meters = z_meters.assign_coords(longitude=lon).sortby(\"longitude\")\n",
        "\n",
        "    steps_arr = np.asarray(steps)\n",
        "    if np.issubdtype(steps_arr.dtype, np.timedelta64):\n",
        "        step_hours = (steps_arr / np.timedelta64(1, \"h\")).astype(int)\n",
        "    else:\n",
        "        step_hours = steps_arr.astype(int)\n",
        "\n",
        "    s0, s1 = window\n",
        "    sel = (step_hours >= s0) & (step_hours <= s1)\n",
        "    if not np.any(sel):\n",
        "        raise ValueError(f\"No steps in {window}. Available: {step_hours.tolist()}\")\n",
        "\n",
        "    # mean height contours over window\n",
        "    z_mean = z_meters.sel(step=steps_arr[sel]).mean(dim=(\"number\",\"step\"))  # [lat, lon]\n",
        "\n",
        "    # weights for unweighting EOFs\n",
        "    wlat = np.sqrt(np.clip(np.cos(np.deg2rad(lat)), 1e-8, None))   # avoid 0 at poles\n",
        "    w2d  = wlat[:, None]\n",
        "\n",
        "    # lon/lat mesh\n",
        "    Lon, Lat = np.meshgrid(z_meters.longitude.values, z_meters.latitude.values)\n",
        "\n",
        "    # default projection for Alaska\n",
        "    if projection is None:\n",
        "        projection = ccrs.LambertConformal(central_longitude=-150, standard_parallels=(55, 65))\n",
        "\n",
        "    figs = []\n",
        "    for k in eof_indices:\n",
        "        # component -> 3D -> window mean\n",
        "        comp = pca.components_[k].reshape(n_steps, n_lat, n_lon)\n",
        "        eof_mean_w = comp[sel].mean(axis=0)                      # weighted space\n",
        "\n",
        "        # 1-sigma scaling (still weighted)\n",
        "        if scale == \"1sigma\":\n",
        "            eof_mean_w = eof_mean_w * np.sqrt(pca.explained_variance_[k])\n",
        "\n",
        "        # unweight back to meters\n",
        "        eof_map = eof_mean_w / w2d\n",
        "\n",
        "        # symmetric color limits if requested\n",
        "        vlim = np.nanmax(np.abs(eof_map)) if symmetric_shade else None\n",
        "\n",
        "        # explained variance (%)\n",
        "        var_pct = 100.0 * float(pca.explained_variance_ratio_[k])\n",
        "\n",
        "        fig = plt.figure(figsize=(9, 5))\n",
        "        ax = plt.axes(projection=projection)\n",
        "\n",
        "        # set extent to your data bbox\n",
        "        ax.set_extent([Lon.min(), Lon.max(), Lat.min(), Lat.max()], crs=ccrs.PlateCarree())\n",
        "\n",
        "        # shaded EOF anomaly\n",
        "        pm = ax.pcolormesh(\n",
        "            Lon, Lat, eof_map, shading=\"auto\", cmap=cmap,\n",
        "            transform=ccrs.PlateCarree(),\n",
        "            **({} if not vlim else {\"vmin\": -vlim, \"vmax\": vlim})\n",
        "        )\n",
        "        cb = plt.colorbar(pm, ax=ax, orientation=\"vertical\", pad=0.02, label=\"EOF anomaly (m)\")\n",
        "\n",
        "        # mean height contours\n",
        "        cs = ax.contour(\n",
        "            Lon, Lat, z_mean, levels=n_contours, colors=\"k\", linewidths=0.8,\n",
        "            transform=ccrs.PlateCarree()\n",
        "        )\n",
        "        ax.clabel(cs, fmt=\"%.0f\", fontsize=8)\n",
        "\n",
        "        # cartographic layers\n",
        "        ax.coastlines(resolution=coast_res, linewidth=0.8)\n",
        "        if add_borders:\n",
        "            ax.add_feature(cfeature.BORDERS.with_scale(coast_res), linewidth=0.6)\n",
        "        if add_states:\n",
        "            ax.add_feature(cfeature.STATES.with_scale(coast_res), linewidth=0.4)\n",
        "\n",
        "        # gridlines with labels\n",
        "        gl = ax.gridlines(draw_labels=True, linewidth=0.4, color=\"gray\", alpha=0.4, linestyle=\"--\")\n",
        "        gl.top_labels = False\n",
        "        gl.right_labels = False\n",
        "\n",
        "        ax.set_title(f\"Mean 500 mb (contours) + EOF{k+1} (shaded), {s0}â€“{s1} h â€” Var: {var_pct:.1f}%\")\n",
        "        plt.tight_layout()\n",
        "        figs.append(fig)\n",
        "\n",
        "    return tuple(figs)\n",
        "\n",
        "\n",
        "def plot_pc_phase_space(\n",
        "    pcs,\n",
        "    labels=None,\n",
        "    member_ids=None,\n",
        "    pca=None,                   # REQUIRED if standardize=True\n",
        "    cluster_centers=None,       # kmeans.cluster_centers_, optional\n",
        "    title=\"Ensemble Phase Space (PC1 vs PC2)\",\n",
        "    annotate=True,\n",
        "    standardize=True,           # <-- NEW: show scores in Ïƒ units\n",
        "    figsize=(7,7)\n",
        "):\n",
        "    pcs = np.asarray(pcs)\n",
        "    if pcs.shape[1] < 2:\n",
        "        raise ValueError(\"pcs must have at least 2 components.\")\n",
        "\n",
        "    # Standardize: divide each PC column by sqrt(eigenvalue)\n",
        "    if standardize:\n",
        "        if pca is None or not hasattr(pca, \"explained_variance_\"):\n",
        "            raise ValueError(\"pca with explained_variance_ is required when standardize=True.\")\n",
        "        sd = np.sqrt(pca.explained_variance_)[:pcs.shape[1]]\n",
        "        S = pcs / sd\n",
        "        if cluster_centers is not None:\n",
        "            centers_plot = np.asarray(cluster_centers) / sd\n",
        "        xlab = f\"PC1 (Ïƒ, {100*pca.explained_variance_ratio_[0]:.1f}%)\"\n",
        "        ylab = f\"PC2 (Ïƒ, {100*pca.explained_variance_ratio_[1]:.1f}%)\"\n",
        "    else:\n",
        "        S = pcs\n",
        "        centers_plot = np.asarray(cluster_centers) if cluster_centers is not None else None\n",
        "        if pca is not None and hasattr(pca, \"explained_variance_ratio_\"):\n",
        "            xlab = f\"PC1 ({100*pca.explained_variance_ratio_[0]:.1f}%)\"\n",
        "            ylab = f\"PC2 ({100*pca.explained_variance_ratio_[1]:.1f}%)\"\n",
        "        else:\n",
        "            xlab, ylab = \"PC1\", \"PC2\"\n",
        "\n",
        "    pc1, pc2 = S[:, 0], S[:, 1]\n",
        "    if labels is None:\n",
        "        labels = np.zeros(len(pc1), dtype=int)\n",
        "    labels = np.asarray(labels)\n",
        "\n",
        "    if member_ids is None:\n",
        "        member_ids = np.arange(len(pc1))\n",
        "    member_ids = np.asarray(member_ids)\n",
        "\n",
        "    uniq = np.unique(labels)\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, max(10, len(uniq))))\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    for i, lab in enumerate(uniq):\n",
        "        sel = labels == lab\n",
        "        ax.scatter(pc1[sel], pc2[sel], s=40, alpha=0.8, label=f\"Cluster {lab} (n={sel.sum()})\", color=colors[i])\n",
        "\n",
        "    if annotate:\n",
        "        for x, y, mid in zip(pc1, pc2, member_ids):\n",
        "            ax.annotate(str(mid), (x, y), fontsize=8, xytext=(3, 3), textcoords=\"offset points\")\n",
        "\n",
        "    if cluster_centers is not None:\n",
        "        ax.scatter(centers_plot[:, 0], centers_plot[:, 1],\n",
        "                   marker=\"*\", s=200, edgecolor=\"k\", facecolor=\"none\", label=\"Centroids\")\n",
        "\n",
        "    ax.set_xlabel(xlab)\n",
        "    ax.set_ylabel(ylab)\n",
        "    ax.set_title(title)\n",
        "    ax.grid(True, linestyle=\"--\", alpha=0.4)\n",
        "    ax.legend(loc=\"best\", frameon=True)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def pick_cluster_representatives(\n",
        "    pcs,\n",
        "    labels,\n",
        "    member_ids,\n",
        "    *,\n",
        "    pca=None,                      # required if standardize=True\n",
        "    standardize=True,              # match your phase-space plot (Ïƒ units)\n",
        "    centers=None,                  # e.g., kmeans.cluster_centers_\n",
        "    n_components=2,                # use PC1..PCn\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns {cluster_label: representative_member_id} where the representative is\n",
        "    the member closest to that cluster's centroid in PC space.\n",
        "\n",
        "    pcs:         (n_members, n_pcs) PCA scores (from pca.transform or fit_transform)\n",
        "    labels:      (n_members,) cluster labels (ints)\n",
        "    member_ids:  (n_members,) identifiers (e.g., ENS numbers)\n",
        "    pca:         fitted PCA (needed if standardize=True)\n",
        "    centers:     (n_clusters, n_pcs) cluster centers in raw PC units (same as pcs)\n",
        "    \"\"\"\n",
        "    pcs = np.asarray(pcs)\n",
        "    labels = np.asarray(labels)\n",
        "    member_ids = np.asarray(member_ids)\n",
        "\n",
        "    if pcs.shape[1] < n_components:\n",
        "        raise ValueError(f\"pcs has only {pcs.shape[1]} components; need >= {n_components}\")\n",
        "\n",
        "    # Standardize to Ïƒ units if requested (divide each PC by sqrt(eigenvalue))\n",
        "    if standardize:\n",
        "        if pca is None or not hasattr(pca, \"explained_variance_\"):\n",
        "            raise ValueError(\"Provide fitted pca when standardize=True.\")\n",
        "        sd = np.sqrt(pca.explained_variance_)[:n_components]\n",
        "        S = pcs[:, :n_components] / sd\n",
        "        if centers is not None:\n",
        "            centers_plot = centers[:, :n_components] / sd\n",
        "        else:\n",
        "            centers_plot = None\n",
        "    else:\n",
        "        S = pcs[:, :n_components]\n",
        "        centers_plot = centers[:, :n_components] if centers is not None else None\n",
        "\n",
        "    reps = {}\n",
        "    uniq = np.unique(labels)\n",
        "    for c in uniq:\n",
        "        mask = labels == c\n",
        "        if not np.any(mask):\n",
        "            continue\n",
        "        Xc = S[mask]  # points in cluster c\n",
        "        mids = member_ids[mask]\n",
        "\n",
        "        # Use provided centers in the same (standardized) space if available; otherwise mean of cluster\n",
        "        if centers_plot is not None:\n",
        "            centroid = centers_plot[c]\n",
        "        else:\n",
        "            centroid = Xc.mean(axis=0)\n",
        "\n",
        "        # Euclidean distance to centroid\n",
        "        d2 = np.sum((Xc - centroid) ** 2, axis=1)\n",
        "        i_local = int(np.argmin(d2))\n",
        "        reps[int(c)] = int(mids[i_local])\n",
        "\n",
        "    return reps\n",
        "\n",
        "def plot_cluster_composites_500hpa(\n",
        "    z_meters,                 # xarray.DataArray [number, step, latitude, longitude] in meters\n",
        "    labels,                   # array-like of cluster labels per member (aligned to member_ids)\n",
        "    member_ids=None,          # array-like of z_meters.number matching labels; if None, assume same order as z_meters.number\n",
        "    window=(120, 168),        # (start_hr, end_hr) time window in hours\n",
        "    clusters_to_show=None,    # list/array of cluster labels to show; if None, first 4 sorted unique\n",
        "    projection=None,          # cartopy CRS; default Lambert Conformal for AK\n",
        "    coast_res=\"50m\",\n",
        "    cmap=\"RdBu_r\",\n",
        "    units=\"m\",                # \"m\" or \"dam\" for contour and anomaly units\n",
        "    n_contours=20,\n",
        "    symmetric_shade=True,\n",
        "    title=\"Cluster composites: mean 500 mb height (contours) + anomaly vs ensemble mean (shaded)\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Builds a 5-panel figure:\n",
        "      Panels 1-4: each cluster's mean height (contours) + anomaly vs ensemble mean (shaded)\n",
        "      Panel 5: total ensemble mean (contours only)\n",
        "    \"\"\"\n",
        "\n",
        "    # --- coords and basic prep\n",
        "    steps = z_meters.step.values\n",
        "    lat   = z_meters.latitude.values\n",
        "    lon   = z_meters.longitude.values\n",
        "\n",
        "    # normalize lon to [-180,180] if needed\n",
        "    if np.nanmax(lon) > 180:\n",
        "        lon = ((lon + 180) % 360) - 180\n",
        "        z_meters = z_meters.assign_coords(longitude=lon).sortby(\"longitude\")\n",
        "\n",
        "    # step mask\n",
        "    steps_arr = np.asarray(steps)\n",
        "    if np.issubdtype(steps_arr.dtype, np.timedelta64):\n",
        "        step_hours = (steps_arr / np.timedelta64(1, \"h\")).astype(int)\n",
        "    else:\n",
        "        step_hours = steps_arr.astype(int)\n",
        "    s0, s1 = window\n",
        "    sel = (step_hours >= s0) & (step_hours <= s1)\n",
        "    if not np.any(sel):\n",
        "        raise ValueError(f\"No steps in window {window}; available: {step_hours.tolist()}\")\n",
        "\n",
        "    # member id alignment\n",
        "    labels = np.asarray(labels)\n",
        "    if member_ids is None:\n",
        "        # assume labels align with z_meters.number order\n",
        "        member_ids = z_meters[\"number\"].values\n",
        "        if labels.shape[0] != member_ids.shape[0]:\n",
        "            raise ValueError(\"labels length does not match z_meters.number; provide member_ids explicitly.\")\n",
        "    else:\n",
        "        member_ids = np.asarray(member_ids)\n",
        "        if labels.shape[0] != member_ids.shape[0]:\n",
        "            raise ValueError(\"labels and member_ids must be same length.\")\n",
        "\n",
        "    # limit the data to members listed in member_ids (in case you dropped some before)\n",
        "    z_sub = z_meters.sel(number=member_ids)\n",
        "\n",
        "    # ensemble mean over provided members + time window\n",
        "    ens_mean = z_sub.sel(step=steps_arr[sel]).mean(dim=(\"number\", \"step\"))  # [lat, lon]\n",
        "\n",
        "    # clusters to show (up to 4)\n",
        "    uniq = np.unique(labels)\n",
        "    if clusters_to_show is None:\n",
        "        clusters_to_show = uniq[:4]\n",
        "    else:\n",
        "        clusters_to_show = np.asarray(clusters_to_show)[:4]\n",
        "\n",
        "    # compute cluster means and anomalies (cluster - ensemble) for color scaling\n",
        "    cluster_fields = []\n",
        "    diffs = []\n",
        "    counts = []\n",
        "    for c in clusters_to_show:\n",
        "        mask = labels == c\n",
        "        counts.append(int(mask.sum()))\n",
        "        if counts[-1] == 0:\n",
        "            # Empty cluster; fill with NaNs\n",
        "            cl_mean = xr.full_like(ens_mean, np.nan)\n",
        "        else:\n",
        "            mids = member_ids[mask]\n",
        "            cl_mean = z_sub.sel(number=mids, step=steps_arr[sel]).mean(dim=(\"number\", \"step\"))\n",
        "        cluster_fields.append(cl_mean)\n",
        "        diffs.append((cl_mean - ens_mean))\n",
        "\n",
        "    # consistent symmetric color limits across cluster panels\n",
        "    if symmetric_shade:\n",
        "        vmax = np.nanmax([np.nanmax(np.abs(d.values)) for d in diffs if d is not None])\n",
        "        if not np.isfinite(vmax) or vmax == 0:\n",
        "            vmax = None\n",
        "    else:\n",
        "        vmax = None\n",
        "\n",
        "    # unit conversion\n",
        "    unit_factor = 1.0 if units == \"m\" else 0.1  # meters->dam\n",
        "    ens_mean_plot = ens_mean * unit_factor\n",
        "    diffs_plot = [d * unit_factor for d in diffs]\n",
        "    cluster_fields_plot = [c * unit_factor for c in cluster_fields]\n",
        "    unit_label = \"m\" if units == \"m\" else \"dam\"\n",
        "\n",
        "    # lon/lat mesh for pcolormesh/contour\n",
        "    Lon, Lat = np.meshgrid(z_meters.longitude.values, z_meters.latitude.values)\n",
        "\n",
        "    # projection default\n",
        "    if projection is None:\n",
        "        projection = ccrs.LambertConformal(central_longitude=-150, standard_parallels=(55, 65))\n",
        "\n",
        "    # --- figure layout: 2 rows x 3 cols; last axis is empty\n",
        "    fig = plt.figure(figsize=(14, 8))\n",
        "    axes = []\n",
        "    for i in range(6):\n",
        "        ax = plt.subplot(2, 3, i+1, projection=projection) if i < 5 else plt.subplot(2, 3, i+1)\n",
        "        axes.append(ax)\n",
        "\n",
        "    # plot 4 cluster panels\n",
        "    for i, (c, cl_mean, diff, n) in enumerate(zip(clusters_to_show, cluster_fields_plot, diffs_plot, counts)):\n",
        "        ax = axes[i]\n",
        "        ax.set_extent([Lon.min(), Lon.max(), Lat.min(), Lat.max()], crs=ccrs.PlateCarree())\n",
        "        # shaded anomaly vs ensemble mean\n",
        "        if vmax is not None:\n",
        "            pm = ax.pcolormesh(Lon, Lat, diff, shading=\"auto\", cmap=cmap,\n",
        "                               vmin=-vmax, vmax=+vmax, transform=ccrs.PlateCarree())\n",
        "        else:\n",
        "            pm = ax.pcolormesh(Lon, Lat, diff, shading=\"auto\", cmap=cmap, transform=ccrs.PlateCarree())\n",
        "        # mean height contours (cluster mean)\n",
        "        cs = ax.contour(Lon, Lat, cl_mean, levels=n_contours, colors=\"k\", linewidths=0.8,\n",
        "                        transform=ccrs.PlateCarree())\n",
        "        ax.clabel(cs, fmt=\"%.0f\" if units == \"m\" else \"%.1f\", fontsize=8)\n",
        "\n",
        "        # cartographic layers\n",
        "        ax.coastlines(resolution=coast_res, linewidth=0.8)\n",
        "        ax.add_feature(cfeature.BORDERS.with_scale(coast_res), linewidth=0.6)\n",
        "        ax.add_feature(cfeature.STATES.with_scale(coast_res), linewidth=0.4)\n",
        "\n",
        "        ax.set_title(f\"Cluster {c} (n={n}); shaded: Î” vs ens mean\")\n",
        "\n",
        "        # add a colorbar only once (right side)\n",
        "        if i == 0:\n",
        "            cax = fig.add_axes([0.92, 0.15, 0.015, 0.7])\n",
        "            cb = fig.colorbar(pm, cax=cax, label=f\"Anomaly ({unit_label})\")\n",
        "\n",
        "    # panel 5: ensemble mean contours only\n",
        "    ax5 = axes[4]\n",
        "    ax5.set_extent([Lon.min(), Lon.max(), Lat.min(), Lat.max()], crs=ccrs.PlateCarree())\n",
        "    cs5 = ax5.contour(Lon, Lat, ens_mean_plot, levels=n_contours, colors=\"k\", linewidths=0.9,\n",
        "                      transform=ccrs.PlateCarree())\n",
        "    ax5.clabel(cs5, fmt=\"%.0f\" if units == \"m\" else \"%.1f\", fontsize=8)\n",
        "    ax5.coastlines(resolution=coast_res, linewidth=0.8)\n",
        "    ax5.add_feature(cfeature.BORDERS.with_scale(coast_res), linewidth=0.6)\n",
        "    ax5.add_feature(cfeature.STATES.with_scale(coast_res), linewidth=0.4)\n",
        "    ax5.set_title(f\"Ensemble mean {unit_label} ({s0}â€“{s1} h)\")\n",
        "\n",
        "    # panel 6: turn off\n",
        "    axes[5].axis(\"off\")\n",
        "\n",
        "    fig.suptitle(title, y=0.98, fontsize=12)\n",
        "    plt.tight_layout(rect=[0, 0, 0.9, 0.96])\n",
        "    return fig\n",
        "\n",
        "\n",
        "\n",
        "########################## Clustering & Plotting ##############################\n",
        "\n",
        "# 1) Load\n",
        "ds = xr.open_dataset(\n",
        "    path,\n",
        "    engine=\"cfgrib\"\n",
        ")\n",
        "\n",
        "# Optional: normalize longitudes to -180..180 if dataset is 0..360\n",
        "if ds.longitude.max() > 180:\n",
        "    ds = ds.assign_coords(longitude=((ds.longitude + 180) % 360) - 180).sortby(\"longitude\")\n",
        "\n",
        "# 2) Subset time + bbox\n",
        "lat_min, lat_max = 40, 75\n",
        "lon_min, lon_max = -179, -125\n",
        "\n",
        "subset = ds.sel(\n",
        "    step=slice(np.timedelta64(tr[0], \"h\"), np.timedelta64(tr[1], \"h\")),\n",
        "    latitude=slice(lat_max, lat_min),      # lat usually decreasing\n",
        "    longitude=slice(lon_min, lon_max)\n",
        ")\n",
        "\n",
        "# 3) Convert to meters\n",
        "z_meters = subset[\"gh\"] / 9.80665   # dims: number, step, latitude, longitude\n",
        "\n",
        "# 4) Latitude weights (sqrt(cos(lat))) over the latitude dimension\n",
        "lat = z_meters[\"latitude\"]\n",
        "wlat = np.sqrt(np.clip(np.cos(np.deg2rad(lat)), 0, None))\n",
        "weights = xr.DataArray(wlat, dims=[\"latitude\"], coords={\"latitude\": lat})\n",
        "\n",
        "# Apply weights (broadcast over step/number/longitude automatically)\n",
        "weighted = z_meters * weights\n",
        "\n",
        "# 5) Stack features AFTER weighting\n",
        "features = weighted.stack(features=(\"step\", \"latitude\", \"longitude\"))  # dims: number, features\n",
        "X = features.values  # shape: [n_members, n_features]\n",
        "\n",
        "# 6) Handle NaNs\n",
        "# Identify members (rows) with any NaNs\n",
        "bad_members_mask = np.any(np.isnan(X), axis=1)\n",
        "\n",
        "if np.any(bad_members_mask):\n",
        "    bad_ids = z_meters['number'].values[bad_members_mask]\n",
        "    print(f\"Dropping members with missing data: {bad_ids}\")\n",
        "\n",
        "    # Keep only rows without NaNs\n",
        "    X = X[~bad_members_mask, :]\n",
        "    member_ids = z_meters['number'].values[~bad_members_mask]\n",
        "else:\n",
        "    print(\"All members have complete data.\")\n",
        "    member_ids = z_meters['number'].values\n",
        "\n",
        "# Weighted anomalies (subtract mean, don't scale by std)\n",
        "X_anoms = StandardScaler(with_mean=True, with_std=False).fit_transform(X)\n",
        "\n",
        "# 7) PCA to 2 components\n",
        "pca = PCA(n_components=2)\n",
        "pcs = pca.fit_transform(X_anoms)\n",
        "print(f\"Explained variance (2 PCs): {pca.explained_variance_ratio_.sum():.2%}\")\n",
        "\n",
        "# 8) K-means in PC space\n",
        "n_clusters = 4\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "labels = kmeans.fit_predict(pcs)\n",
        "\n",
        "# 9) Members per cluster\n",
        "clusters = {i: [] for i in range(n_clusters)}\n",
        "for m_idx, cid in enumerate(labels):\n",
        "    clusters[cid].append(int(z_meters[\"number\"][m_idx].values))\n",
        "\n",
        "for cid, members in clusters.items():\n",
        "    print(f\"Cluster {cid}: {members}\")\n",
        "\n",
        "# Plotting EOFs\n",
        "fig1, fig2 = plot_mean_height_with_eof_shade_cartopy(\n",
        "    z_meters, pca,\n",
        "    window=tr,\n",
        "    eof_indices=(0, 1),\n",
        "    projection=ccrs.NorthPolarStereo(central_longitude=-150, true_scale_latitude=60),\n",
        "    scale=\"1sigma\"            # 1-Ïƒ amplitude patterns (meters)\n",
        ")\n",
        "\n",
        "# Plotting phase space\n",
        "member_ids = z_meters[\"number\"].values    # or the filtered array if you dropped members\n",
        "\n",
        "fig = plot_pc_phase_space(\n",
        "    pcs=pcs,\n",
        "    labels=labels,\n",
        "    member_ids=member_ids,\n",
        "    pca=pca,\n",
        "    cluster_centers=getattr(kmeans, \"cluster_centers_\", None),\n",
        "    title=\"ECMWF ENS 500 hPa â€” Phase Space (PC1 vs PC2)\"\n",
        ")\n",
        "\n",
        "representatives = pick_cluster_representatives(\n",
        "    pcs=pcs,\n",
        "    labels=labels,\n",
        "    member_ids=member_ids,\n",
        "    pca=pca,\n",
        "    standardize=True,                       # matches your standardized phase-space\n",
        "    centers=getattr(kmeans, \"cluster_centers_\", None),\n",
        "    n_components=2\n",
        ")\n",
        "\n",
        "print(representatives)\n",
        "\n",
        "fig = plot_cluster_composites_500hpa(\n",
        "    z_meters=z_meters,\n",
        "    labels=labels,\n",
        "    member_ids=member_ids,     # if you didn't drop any, you can omit this\n",
        "    window=tr,\n",
        "    units=\"m\"                # contours + anomalies in decameters\n",
        ")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "a0TWMGSzq69u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Plot Representative Member**"
      ],
      "metadata": {
        "id": "S_R38ww_q-DE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.colors as mcolors\n",
        "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "def make_custom_cmaps(name, colors, bounds: list = None, N: int = None):\n",
        "    if N is None:\n",
        "        N = len(colors)\n",
        "    linear_cmap = mcolors.LinearSegmentedColormap.from_list(name, colors)\n",
        "    segment_cmap = mcolors.LinearSegmentedColormap.from_list(name + \"2\", colors, N=N)\n",
        "\n",
        "    # When data is NaN, set color to transparent\n",
        "    linear_cmap.set_bad(\"#ffffff00\")\n",
        "    segment_cmap.set_bad(\"#ffffff00\")\n",
        "\n",
        "    for cm in [linear_cmap, segment_cmap]:\n",
        "        mpl.colormaps.register(cmap=cm, force=True)\n",
        "        mpl.colormaps.register(cmap=cm.reversed(), force=True)\n",
        "\n",
        "    if bounds is not None:\n",
        "        return (\n",
        "            mcolors.Normalize(bounds.min(), bounds.max()),\n",
        "            mcolors.BoundaryNorm(bounds, linear_cmap.N),\n",
        "        )\n",
        "\n",
        "\n",
        "class NWSPrecipitation:\n",
        "    \"\"\"National Weather Service precipitation amount colorbar properties.\n",
        "\n",
        "    Also known as Qualitative Precipitation Forecast/Estimate (QPF/QPE).\n",
        "    \"\"\"\n",
        "\n",
        "    name = \"nws.pcp\"\n",
        "    units = \"in\"\n",
        "    variable = \"Precipitation\"\n",
        "    colors = np.array(\n",
        "        [\n",
        "            \"#ffffff\",\n",
        "            \"#c7e9c0\",\n",
        "            \"#a1d99b\",\n",
        "            \"#74c476\",\n",
        "            \"#31a353\",\n",
        "            \"#006d2c\",\n",
        "            \"#fffa8a\",\n",
        "            \"#ffcc4f\",\n",
        "            \"#fe8d3c\",\n",
        "            \"#fc4e2a\",\n",
        "            \"#d61a1c\",\n",
        "            \"#ad0026\",\n",
        "            \"#700026\",\n",
        "            \"#3b0030\",\n",
        "            \"#4c0073\",\n",
        "            \"#ffdbff\",\n",
        "        ]\n",
        "    )\n",
        "    # NWS bounds in inches\n",
        "    bounds = np.array(\n",
        "        [0, 0.01, 0.1, 0.25, 0.5, 1, 1.5, 2, 3, 4, 6, 8, 10, 15, 20, 30, 50]\n",
        "    )\n",
        "    norm, norm2 = make_custom_cmaps(name, colors, bounds)\n",
        "    cmap = plt.get_cmap(name)\n",
        "    cmap2 = plt.get_cmap(name + \"2\")\n",
        "    kwargs = dict(cmap=cmap, norm=norm)\n",
        "    kwargs2 = dict(cmap=cmap, norm=norm2)\n",
        "    cbar_kwargs = dict(label=f\"{variable} ({units})\")\n",
        "    cbar_kwargs2 = cbar_kwargs | dict(spacing=\"uniform\", ticks=bounds)\n",
        "\n",
        "def mm_to_in(mm):\n",
        "  return mm * 0.0393701\n",
        "\n",
        "def plot_msl_with_tp6h(\n",
        "    ds,\n",
        "    *,\n",
        "    lat_min=50, lat_max=72,\n",
        "    lon_min=-180, lon_max=-130,\n",
        "    projection=None,\n",
        "    coast_res=\"50m\",\n",
        "    tp_mm_max=4,            # colorbar cap for 6-h precip (in)\n",
        "    n_contours=20,\n",
        "    clip_negative=True       # clip tiny negative diffs to 0\n",
        "):\n",
        "    \"\"\"\n",
        "    Plots one map per 6-h accumulation step:\n",
        "      - MSLP (hPa) as contours\n",
        "      - 6-h precipitation (mm) as shaded\n",
        "\n",
        "    Assumes ds has cumulative 'tp' (meters) at steps including the previous step.\n",
        "    The first original step is NOT plotted; tp6 is aligned to the 'upper' steps only.\n",
        "    \"\"\"\n",
        "    # Normalize longitudes to [-180, 180] if needed\n",
        "    if float(ds.longitude.max()) > 180:\n",
        "        ds = ds.assign_coords(longitude=((ds.longitude + 180) % 360) - 180).sortby(\"longitude\")\n",
        "\n",
        "    # Subset bbox (lat usually decreasing in GRIB)\n",
        "    ds_box = ds.sel(latitude=slice(lat_max, lat_min), longitude=slice(lon_min, lon_max))\n",
        "\n",
        "    # Convert units\n",
        "    msl_hpa = ds_box[\"msl\"] / 100.0         # Pa -> hPa\n",
        "    tp_cum  = ds_box[\"tp\"]                  # meters, cumulative since T0\n",
        "\n",
        "    # 6-h accumulation (mm), aligned to the upper step (e.g., 168, 174, â€¦)\n",
        "    tp6 = tp_cum.diff(\"step\", label=\"upper\") * 1000.0\n",
        "    tp6 = mm_to_in(tp6)  # in\n",
        "    if clip_negative:\n",
        "        tp6 = xr.where(tp6 < 0, 0, tp6)\n",
        "\n",
        "    # Mesh for plotting\n",
        "    Lon, Lat = np.meshgrid(ds_box.longitude.values, ds_box.latitude.values)\n",
        "\n",
        "    # Projection\n",
        "    if projection is None:\n",
        "        projection = ccrs.LambertConformal(central_longitude=-150, standard_parallels=(55, 65))\n",
        "\n",
        "    # Optional: check spacing ~6h\n",
        "    if \"timedelta64\" in str(ds_box.step.dtype):\n",
        "        dh = (ds_box.step.diff(\"step\") / np.timedelta64(1, \"h\")).astype(float)\n",
        "        if not np.allclose(dh, 6.0):\n",
        "            print(\"âš ï¸  Step spacing is not uniformly 6 h; plotting interval accumulations as-is.\")\n",
        "\n",
        "    # Loop over *tp6* steps (skips the first original step by construction)\n",
        "    for i, step_val in enumerate(tp6.step.values):\n",
        "        z = msl_hpa.sel(step=step_val)\n",
        "        p = tp6.sel(step=step_val)\n",
        "\n",
        "        fig = plt.figure(figsize=(10, 6))\n",
        "        ax = plt.axes(projection=projection)\n",
        "        ax.set_extent([Lon.min(), Lon.max(), Lat.min(), Lat.max()], crs=ccrs.PlateCarree())\n",
        "\n",
        "        # shaded 6-h precip (mm)\n",
        "        #pm = ax.pcolormesh(Lon, Lat, p, cmap=cmap, shading=\"auto\",\n",
        "        #                   vmin=0, vmax=tp_mm_max, transform=ccrs.PlateCarree())\n",
        "        kwargs = NWSPrecipitation.kwargs2\n",
        "        cbar_kwargs = NWSPrecipitation.cbar_kwargs2\n",
        "\n",
        "        pm = ax.pcolormesh(Lon, Lat, p, transform=ccrs.PlateCarree(), **kwargs)\n",
        "        plt.colorbar(pm, ax=ax, pad=0.02, **cbar_kwargs)\n",
        "\n",
        "        # MSLP contours (hPa)\n",
        "        cs = ax.contour(Lon, Lat, z, levels=n_contours, colors=\"k\", linewidths=0.8,\n",
        "                        transform=ccrs.PlateCarree())\n",
        "        ax.clabel(cs, fmt=\"%.0f\", fontsize=8)\n",
        "\n",
        "        # carto layers\n",
        "        ax.coastlines(resolution=coast_res, linewidth=0.8)\n",
        "        ax.add_feature(cfeature.BORDERS.with_scale(coast_res), linewidth=0.6)\n",
        "        ax.add_feature(cfeature.STATES.with_scale(coast_res), linewidth=0.4)\n",
        "        gl = ax.gridlines(draw_labels=True, linewidth=0.4, color=\"gray\", alpha=0.4, linestyle=\"--\")\n",
        "        gl.top_labels = False\n",
        "        gl.right_labels = False\n",
        "\n",
        "        # Title\n",
        "        # Title\n",
        "        if \"valid_time\" in ds_box:\n",
        "            vt = ds_box.valid_time.sel(step=step_val).values  # numpy.datetime64\n",
        "            # ensure numpy datetime64 and format to hour\n",
        "            tstr = np.datetime_as_string(np.asarray(vt, dtype=\"datetime64[ns]\"), unit=\"h\")\n",
        "        else:\n",
        "            # fall back to lead time\n",
        "            if np.issubdtype(ds_box.step.dtype, np.timedelta64):\n",
        "                lead_h = int(step_val / np.timedelta64(1, \"h\"))\n",
        "                tstr = f\"T+{lead_h:02d} h\"\n",
        "            else:\n",
        "                tstr = str(step_val)\n",
        "        ax.set_title(f\"MSLP (hPa) contours + 6-h precip (mm) shaded â€” {tstr}\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "#@markdown Which cluster do you want to see?\n",
        "cluster = 1 #@param [0,1,2,3]\n",
        "#@markdown Which variable do you want to plot?\n",
        "wxvar = \"MSLP_Precip\" #@param [\"MSLP_Precip\"]\n",
        "\n",
        "#@markdown What time frame do you want to see?\n",
        "timeframe = \"Day7\" #@param [\"Day5\", \"Day6\", \"Day7\", \"Day8\", \"Day9\", \"Day5-7\", \"Day6-8\", \"Day7-9\", \"Day5-8\", \"Day6-9\"]\n",
        "timeranges = {\n",
        "    \"Day5\": (120, 144),\n",
        "    \"Day6\": (144, 168),\n",
        "    \"Day7\": (168, 192),\n",
        "    \"Day8\": (192, 216),\n",
        "    \"Day9\": (216, 240),\n",
        "    \"Day5-7\": (120, 192),\n",
        "    \"Day6-8\": (144, 216),\n",
        "    \"Day7-9\": (168, 240),\n",
        "    \"Day5-8\": (120, 216),\n",
        "    \"Day6-9\": (144, 240),\n",
        "}\n",
        "tr = timeranges[timeframe]\n",
        "vardict = {\n",
        "    \"MSLP_Precip\": \"MSLP\",\n",
        "}\n",
        "\n",
        "if wxvar == \"MSLP_Precip\":\n",
        "    #getting MSL\n",
        "    path1 = download_ecmwf_ens(\n",
        "        param=['msl', 'tp'],\n",
        "        init_time=datetime.strptime(f\"{init_date} {init_time}:00\", \"%Y-%m-%d %H:%M\"),\n",
        "        steps=list(range(tr[0]-6, tr[1], 6)),\n",
        "        level_type=\"sfc\",\n",
        "        members=[representatives[cluster]],\n",
        "        target_dir=\".\",\n",
        "        source=\"ecmwf\"\n",
        "    )\n",
        "\n",
        "#path1 = \"ecmwf_ens_msl_tp_sfc_2025081100.grib2\"\n",
        "# 1) Load\n",
        "ds = xr.open_dataset(\n",
        "    path1,\n",
        "    engine=\"cfgrib\"\n",
        ")\n",
        "# ds is your Dataset with coords and variables: step, latitude, longitude, msl, tp\n",
        "plot_msl_with_tp6h(\n",
        "    ds,\n",
        "    lat_min=50, lat_max=75,\n",
        "    lon_min=-180, lon_max=-125,\n",
        "    tp_mm_max=30,              # adjust colorbar cap as you like\n",
        "    n_contours=20\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mdXbkeRRU6Lk",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "k6DRBRAXCyNh",
        "pNRHFuNmC-2K"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \n[Clang 13.0.1 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "d9efab89797b4f7e4129f7fe7c375038c6a3f1b6c83da7efdea02c4da588d5be"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}